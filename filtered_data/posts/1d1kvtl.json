{
    "_meta": {
        "retrieved_2nd_on": 1716919655
    },
    "all_awardings": [],
    "allow_live_comments": false,
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "author": "JoshuaStarAuthor",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_ox9zzaptt",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "can_gild": false,
    "can_mod_post": false,
    "category": null,
    "clicked": false,
    "content_categories": null,
    "contest_mode": false,
    "created": 1716790044,
    "created_utc": 1716790044,
    "discussion_type": null,
    "distinguished": null,
    "domain": "self.ChatGPT",
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "hidden": false,
    "hide_score": false,
    "id": "1d1kvtl",
    "is_created_from_ads_ui": false,
    "is_crosspostable": true,
    "is_meta": false,
    "is_original_content": false,
    "is_reddit_media_domain": false,
    "is_robot_indexable": true,
    "is_self": true,
    "is_video": false,
    "likes": null,
    "link_flair_background_color": "#ddbd37",
    "link_flair_css_class": "",
    "link_flair_richtext": [
        {
            "e": "text",
            "t": "News \ud83d\udcf0"
        }
    ],
    "link_flair_template_id": "1c39d510-f1ac-11ed-8167-5e7479c0f87c",
    "link_flair_text": "News \ud83d\udcf0",
    "link_flair_text_color": "light",
    "link_flair_type": "richtext",
    "locked": false,
    "media": null,
    "media_embed": {},
    "media_only": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t3_1d1kvtl",
    "no_follow": true,
    "num_comments": 6,
    "num_crossposts": 0,
    "num_reports": null,
    "over_18": false,
    "parent_whitelist_status": "all_ads",
    "permalink": "/r/ChatGPT/comments/1d1kvtl/ai_firms_mustnt_govern_themselves_say_exmembers/",
    "pinned": false,
    "post_hint": "self",
    "preview": {
        "enabled": false,
        "images": [
            {
                "id": "lxgM0IXwQcovdK7d6ncI0nB2ahSAx4D-i-fpJbVOEJA",
                "resolutions": [
                    {
                        "height": 60,
                        "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?width=108&crop=smart&auto=webp&s=80fffcbbd0d0c7184bebe84b7e5c8b68b54d1b0d",
                        "width": 108
                    },
                    {
                        "height": 121,
                        "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?width=216&crop=smart&auto=webp&s=5b217d400a812f99709fe2e6df26a407d76938c0",
                        "width": 216
                    },
                    {
                        "height": 180,
                        "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?width=320&crop=smart&auto=webp&s=a2f96c8584e7b7c5657915698448d168be218f0b",
                        "width": 320
                    },
                    {
                        "height": 360,
                        "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?width=640&crop=smart&auto=webp&s=12d7716836fb0bb7b16de6643c52ed9f912f5ec5",
                        "width": 640
                    },
                    {
                        "height": 540,
                        "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?width=960&crop=smart&auto=webp&s=07780c1e17837b637e6b9760fe640396ee0ed0e0",
                        "width": 960
                    },
                    {
                        "height": 607,
                        "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?width=1080&crop=smart&auto=webp&s=ea46a6688c5ddae629080ebac4fda1b8ebaad576",
                        "width": 1080
                    }
                ],
                "source": {
                    "height": 720,
                    "url": "https://external-preview.redd.it/xizY1Ag1SdYwy0UMJkhmwZvpRkBaMvmPtkekPc1mxqw.jpg?auto=webp&s=271b0c330da2066181cce44d82f2fdef0f050527",
                    "width": 1280
                },
                "variants": {}
            }
        ]
    },
    "pwls": 6,
    "quarantine": false,
    "removal_reason": null,
    "removed_by": null,
    "removed_by_category": null,
    "report_reasons": null,
    "retrieved_on": 1716791789,
    "saved": false,
    "score": 2,
    "secure_media": null,
    "secure_media_embed": {},
    "selftext": "https://www.economist.com/by-invitation/2024/05/26/ai-firms-mustnt-govern-themselves-say-ex-members-of-openais-board\n\nFor humanity\u2019s sake, regulation is needed to tame market forces, argue Helen Toner and Tasha McCauley. \n\nCan private companies pushing forward the frontier of a revolutionary new technology be expected to operate in the interests of both their shareholders and the wider world? When we were recruited to the board of OpenAI\u2014Tasha in 2018 and Helen in 2021\u2014we were cautiously optimistic that the company\u2019s innovative approach to self-governance could offer a blueprint for responsible ai development. But based on our experience, we believe that self-governance cannot reliably withstand the pressure of profit incentives. With ai\u2019s enormous potential for both positive and negative impact, it\u2019s not sufficient to assume that such incentives will always be aligned with the public good. For the rise of ai to benefit everyone, governments must begin building effective regulatory frameworks now.\n\nIf any company could have successfully governed itself while safely and ethically developing advanced ai systems, it would have been OpenAI. The organisation was originally established as a non-profit with a laudable mission: to ensure that agi, or artificial general intelligence\u2014ai systems that are generally smarter than humans\u2014would benefit \u201call of humanity\u201d. Later, a for-profit subsidiary was created to raise the necessary capital, but the non-profit stayed in charge. The stated purpose of this unusual structure was to protect the company\u2019s ability to stick to its original mission, and the board\u2019s mandate was to uphold that mission. It was unprecedented, but it seemed worth trying. Unfortunately it didn\u2019t work.\n\nLast November, in an effort to salvage this self-regulatory structure, the OpenAI board dismissed its ceo, Sam Altman. The board\u2019s ability to uphold the company\u2019s mission had become increasingly constrained due to long-standing patterns of behaviour exhibited by Mr Altman, which, among other things, we believe undermined the board\u2019s oversight of key decisions and internal safety protocols. Multiple senior leaders had privately shared grave concerns with the board, saying they believed that Mr Altman cultivated \u201ca toxic culture of lying\u201d and engaged in \u201cbehaviour [that] can be characterised as psychological abuse\u201d. According to OpenAI, an internal investigation found that the board had \u201cacted within its broad discretion\u201d to dismiss Mr Altman, but also concluded that his conduct did not \u201cmandate removal\u201d. OpenAI relayed few specifics justifying this conclusion, and it did not make the investigation report available to employees, the press or the public.\n\nThe question of whether such behaviour should generally \u201cmandate removal\u201d of a ceo is a discussion for another time. But in OpenAI\u2019s specific case, given the board\u2019s duty to provide independent oversight and protect the company\u2019s public-interest mission, we stand by the board\u2019s action to dismiss Mr Altman. We also feel that developments since he returned to the company\u2014including his reinstatement to the board and the departure of senior safety-focused talent\u2014bode ill for the OpenAI experiment in self-governance.\n\nOur particular story offers the broader lesson that society must not let the roll-out of ai be controlled solely by private tech companies. Certainly, there are numerous genuine efforts in the private sector to guide the development of this technology responsibly, and we applaud those efforts. But even with the best of intentions, without external oversight, this kind of self-regulation will end up unenforceable, especially under the pressure of immense profit incentives. Governments must play an active role.\n\nAnd yet, in recent months, a rising chorus of voices\u2014from Washington lawmakers to Silicon Valley investors\u2014has advocated minimal government regulation of ai. Often, they draw parallels with the laissez-faire approach to the internet in the 1990s and the economic growth it spurred. However, this analogy is misleading.\n\nInside ai companies, and throughout the larger community of researchers and engineers in the field, the high stakes\u2014and large risks\u2014of developing increasingly advanced ai are widely acknowledged. In Mr Altman\u2019s own words, \u201cSuccessfully transitioning to a world with superintelligence is perhaps the most important\u2014and hopeful, and scary\u2014project in human history.\u201d The level of concern expressed by many top ai scientists about the technology they themselves are building is well documented and very different from the optimistic attitudes of the programmers and network engineers who developed the early internet.\n\nIt is also far from clear that light-touch regulation of the internet has been an unalloyed good for society. Certainly, many successful tech businesses\u2014and their investors\u2014have benefited enormously from the lack of constraints on commerce online. It is less obvious that societies have struck the right balance when it comes to regulating to curb misinformation and disinformation on social media, child exploitation and human trafficking, and a growing youth mental-health crisis.\n\nGoods, infrastructure and society are improved by regulation. It\u2019s because of regulation that cars have seat belts and airbags, that we don\u2019t worry about contaminated milk and that buildings are constructed to be accessible to all. Judicious regulation could ensure the benefits of ai are realised responsibly and more broadly. A good place to start would be policies that give governments more visibility into how the cutting edge of ai is progressing, such as transparency requirements and incident-tracking.\n\nOf course, there are pitfalls to regulation, and these must be managed. Poorly designed regulation can place a disproportionate burden on smaller companies, stifling competition and innovation. It is crucial that policymakers act independently of leading ai companies when developing new rules. They must be vigilant against loopholes, regulatory \u201cmoats\u201d that shield early movers from competition, and the potential for regulatory capture. Indeed, Mr Altman\u2019s own calls for ai regulation must be understood in the context of these pitfalls as having potentially self-serving ends. An appropriate regulatory framework will require agile adjustments, keeping pace with the world\u2019s expanding grasp of ai\u2019s capabilities.\n\nUltimately, we believe in ai\u2019s potential to boost human productivity and well-being in ways never before seen. But the path to that better future is not without peril. OpenAI was founded as a bold experiment to develop increasingly capable ai while prioritising the public good over profits. Our experience is that even with every advantage, self-governance mechanisms like those employed by OpenAI will not suffice. It is, therefore, essential that the public sector be closely involved in the development of the technology. Now is the time for governmental bodies around the world to assert themselves. Only through a healthy balance of market forces and prudent regulation can we reliably ensure that ai\u2019s evolution truly benefits all of humanity.\n",
    "send_replies": true,
    "spoiler": false,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_subscribers": 5646136,
    "subreddit_type": "public",
    "suggested_sort": null,
    "thumbnail": "self",
    "thumbnail_height": null,
    "thumbnail_width": null,
    "title": "AI firms mustn\u2019t govern themselves, say ex-members of OpenAI\u2019s board  (no paywall)",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "ups": 2,
    "upvote_ratio": 0.5799999833106995,
    "url": "https://www.reddit.com/r/ChatGPT/comments/1d1kvtl/ai_firms_mustnt_govern_themselves_say_exmembers/",
    "user_reports": [],
    "view_count": null,
    "visited": false,
    "whitelist_status": "all_ads",
    "wls": 6
}