{
    "_meta": {
        "retrieved_2nd_on": 1712997583
    },
    "all_awardings": [],
    "allow_live_comments": false,
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "author": "Bezbozny",
    "author_flair_background_color": "",
    "author_flair_css_class": null,
    "author_flair_richtext": [
        {
            "a": ":Discord:",
            "e": "emoji",
            "u": "https://emoji.redditmedia.com/0zlhaela6zub1_t5_7hqomg/Discord"
        }
    ],
    "author_flair_template_id": null,
    "author_flair_text": ":Discord:",
    "author_flair_text_color": "dark",
    "author_flair_type": "richtext",
    "author_fullname": "t2_il4n2",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "can_gild": false,
    "can_mod_post": false,
    "category": null,
    "clicked": false,
    "content_categories": null,
    "contest_mode": false,
    "created": 1712867972,
    "created_utc": 1712867972,
    "discussion_type": null,
    "distinguished": null,
    "domain": "self.ChatGPT",
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "hidden": false,
    "hide_score": false,
    "id": "1c1pmt4",
    "is_created_from_ads_ui": false,
    "is_crosspostable": true,
    "is_meta": false,
    "is_original_content": false,
    "is_reddit_media_domain": false,
    "is_robot_indexable": true,
    "is_self": true,
    "is_video": false,
    "likes": null,
    "link_flair_background_color": "#ff66ac",
    "link_flair_css_class": "",
    "link_flair_richtext": [
        {
            "e": "text",
            "t": "Serious replies only "
        },
        {
            "a": ":closed-ai:",
            "e": "emoji",
            "u": "https://emoji.redditmedia.com/kiux00uuphia1_t5_7hqomg/closed-ai"
        }
    ],
    "link_flair_template_id": "c660b6fa-7be9-11ed-974b-1eca573371bf",
    "link_flair_text": "Serious replies only :closed-ai:",
    "link_flair_text_color": "light",
    "link_flair_type": "richtext",
    "locked": false,
    "media": null,
    "media_embed": {},
    "media_only": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t3_1c1pmt4",
    "no_follow": true,
    "num_comments": 3,
    "num_crossposts": 0,
    "num_reports": null,
    "over_18": false,
    "parent_whitelist_status": "all_ads",
    "permalink": "/r/ChatGPT/comments/1c1pmt4/laymen_view_of_llm_architecture_is_this_analogy/",
    "pinned": false,
    "pwls": 6,
    "quarantine": false,
    "removal_reason": null,
    "removed_by": null,
    "removed_by_category": null,
    "report_reasons": null,
    "retrieved_on": 1712867986,
    "saved": false,
    "score": 2,
    "secure_media": null,
    "secure_media_embed": {},
    "selftext": "So when talking to an LLM, gemini, mixtral, chatgpt, etc, it can remember your conversations to a degree based on the size of its \"Context window\", and its \"Model weights\" or \"Parameters\" or whatever make up its general personality for how it will respond regardless of whats in the context window.  \nWould you say that the context window is kind of like its short term memory, and its weights are like its long term memory? Right now, what you put into the context window doesn't seem to alter the model, but is that an arbitrary limitation? Could a switch be flipped such that the weights were incrementally and constantly being updated to alter its \"personality\" just like how parts of our personality are constantly being altered by portions of our short term memory being naturally uploaded into long term?",
    "send_replies": true,
    "spoiler": false,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_subscribers": 5045541,
    "subreddit_type": "public",
    "suggested_sort": null,
    "thumbnail": "self",
    "thumbnail_height": null,
    "thumbnail_width": null,
    "title": "Laymen view of LLM architecture: is this analogy close to correct?",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "ups": 2,
    "upvote_ratio": 0.75,
    "url": "https://www.reddit.com/r/ChatGPT/comments/1c1pmt4/laymen_view_of_llm_architecture_is_this_analogy/",
    "user_reports": [],
    "view_count": null,
    "visited": false,
    "whitelist_status": "all_ads",
    "wls": 6
}