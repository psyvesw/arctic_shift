{
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "RinArenna",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_8cfne",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Really? It's easy as hell, at least was on Python.\n\nIt's simple as hell.\n\nYou create a Pinecone db instance and set it to the specs of OpenAI's embedding API and convert messages into a  Vector. Every message is stored by vector in Pinecone. Then you use Pinecone's API to retrieve messages based on distance between the vector of your current message and the vectors of messages in Pinecone's db. That's the **hardest** part.\n\nFor GPT you just use their python api you used from earlier. You take the user's message, convert it to a vector, retrieve similar vectors from Pinecone then put the similar messages in the system prompt. Pass those to GPT and it'll automatically reference the messages as memories.\n\nThe commands are easy too. You can split up GPT into two phases. The first uses a system prompt to instruct GPT to return a command call you list. You parse the message and pass the arguments to your own scripts. You can make them plug-ins if you're an overacheiver. You just step through an array of objects you make by using a require on every file in a folder, and put all your python files in there. \n\nThen you pass the output in the system prompt with the Pinecone retrieved messages.\n\nIt's not hard, even an amateur could set that up.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1717273726,
    "created_utc": 1717273726,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6oa8qt",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d5haqv",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6oa8qt",
    "no_follow": false,
    "num_reports": null,
    "parent_id": "t1_l6ncj6a",
    "permalink": "/r/ChatGPT/comments/1d5haqv/anthropics_chief_of_staff_thinks_agi_is_almost/l6oa8qt/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717273740,
    "saved": false,
    "score": 1,
    "score_hidden": true,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}