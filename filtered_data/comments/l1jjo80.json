{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1714376286
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "OneOnOne6211",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_6inwf8q4",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Because it is useful to retreive information...\n\nNot sure what the confusion is here. Talking to ChatGPT allows you to find information (theoretically) in a way that aligns more with our natural way of finding out information (through two-way conversation) than a search engine. So we gravitate towards doing that.\n\nLike it or not, people do find it useful to use it in that way. And that is a function people want from it. As such, I'd say it would be much better if it were more factually accurate.\n\nI absolutely agree that people should be careful and double check when it comes to asking ChatGPT for facts. But that's not because inherently the technology should not be used as such. It's just a limitation of the technology currently. Hopefully over time it will become far more truthful so that it can be used more easily in this way.\n\nIt's also not helpful that ChatGPT \"lies\" in a way that is completely indistinguishable from when it is being truthful. Obviously because it is not human and doesn't think about \"lying\" any more than a toaster would, nor have any filter to truly prevent it. Which means that sometimes ChatGPT can be quite reliable, and other times it just randomly hallucinates.\n\nPeople need to remember that, of course, but again that's a limitation of the technology as it exists.\n\nIt's also worth noting that mistruths are everywhere. Looking through the internet with Google you are also quite likely to find web pages where people are lying or mistaken and full of misinformation. So it's not like ChatGPT is alone in this as a source. It's just that when checking on web pages you can do things like look up the source, for example, to see if it's generally reliable. FlatEarthers.com is probably not going to give you great info about the moonlanding. But you can't do that with ChatGPT.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714246680,
    "created_utc": 1714246680,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l1jjo80",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1celrvi",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l1jjo80",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1celrvi",
    "permalink": "/r/ChatGPT/comments/1celrvi/can_we_please_get_this_controversial/l1jjo80/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714246696,
    "saved": false,
    "score": 27,
    "score_hidden": false,
    "send_replies": false,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 27,
    "user_reports": []
}