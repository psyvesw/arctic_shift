{
    "_meta": {
        "retrieved_2nd_on": 1712217203
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "BeingBalanced",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_anvhhhy6j",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Eh, doing lots more testing, I see what drawback on Perplexity. In doing some research on clinical studies I've been giving it some hard tasks and flipping between Claude 3 Opus and GPT-4-Turbo the comparing to Microsoft Copilot which I'm on a trial of their Pro but not sure if that really makes a big difference in precise mode, guess it just guarantees I'm using GPT-4 all the time.\n\nThe strange issue I'm seeing is that Perplexity, even on GPT-4-Turbo is coming up with ZERO web search results (I wonder how the size of their web search database compares to Google and Bing?) and so the response has no data source citations (I had academic mode turned on).  \n\nPutting the same prompt into  Copilot, I get a much more abbreviated response, Perplexity was WAY more comprehensive yet CoPilot cited the source data.  \n\nSo it appears the only shortcoming of Perplexity is it's web search database isn't as large as Google (of course) and Bing.  So it appears only CoPilot or OpenAI's GPT-4 may have access to the Bing Database so it can find more sources than Perplexity even when using GPT-4-Turbo.  However I'm using prompts on subject matter I'm already an expert in and Perplexity, even without any web results to cite as sources using the GTP-4-Turbo engine was very correct and comprehensive.  It actually was better than the response using Claude 3 Opus as the model.\n\nIn a nutshell, nothing is going to be perfect but Perplexity appears to clearly have more major advantages than disadvantages, especially for professional research use, when compared to the other tools.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1712087590,
    "created_utc": 1712087590,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "kxqwqhh",
    "is_submitter": true,
    "likes": null,
    "link_id": "t3_1bu3gc5",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_kxqwqhh",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_kxq26a3",
    "permalink": "/r/ChatGPT/comments/1bu3gc5/your_top_real_world_uses_for_ai_chat_bots_and/kxqwqhh/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1712087606,
    "saved": false,
    "score": 2,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 2,
    "user_reports": []
}