{
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Use-Useful",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_7ydyz6hz",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "TL/DR: it's not that it isn't useful to experts, you are just trying to use a screw driver as a hammer.\n\n\nLLMs more or less try to make probabilisticly plausible text, as based on their training corpus. The thing is that the things you are asking it for are pretty rarely written about. Things LIKE it are written about all the time. So it knows the form of the answer, but not the specifics. LLMs are not encyclopedic, they can do expert guidance only where there is a large amount of training material.\n\n\nFor example, if I ask it a beginner programming problem, it will have millions of similar problems in its training set I'd guess, many of which are identical to my question. But if I ask it about a more niche issue like memory management in that same language, where the topic perhaps is more like dozens or hundreds of times, it starts to get misleading. If I ask it about something only written about a few times or not at all, it will make up plausible sounding crap.\n\n\nYour situation is in the last category.\n\n\nBasically, what you got it to do, is not something it is good at. It's not that it's not useful to experts(I have a phd myself, dozens of publications/patents, I feel safe in saying this), it's that you are using the tool for something it isn't good at.\n\n\nPersonally I use it for reference in adjacent fields to my own as sortof a \"explain to me this concept\", where its outside my experience but close enough that I can tell if it screwed up badly, and common enough that it is unlikely to.\u00a0\n\n\nAlso, it is a Large LANGUAGE Model - I use it to dynamically produce language content quite a bit for various tasks.\n\n\nBtw, The thing I WANT it to be good at, that its currently bad at, is literature review performed by fetching from the web :/\u00a0",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1717349375,
    "created_utc": 1717349375,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6sjmsk",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d6evjy",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6sjmsk",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1d6evjy",
    "permalink": "/r/ChatGPT/comments/1d6evjy/useless_for_experts_gpt4_got_every_single_fact/l6sjmsk/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717349388,
    "saved": false,
    "score": 1,
    "score_hidden": true,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}