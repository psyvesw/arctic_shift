{
    "_meta": {
        "retrieved_2nd_on": 1716745808
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "JollyToby0220",
    "author_cakeday": true,
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_aowoo3mf",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Well the initial training is done via unsupervised learning. You split text sources into the input and output and the model should predict the output given the input.\u00a0\nThis is effectively the pre-training phase. But this has the downside that if you enter a question, you don\u2019t get a solid answer. So next phase is training via Reinforcement Learning. Reinforcement Learning is quite complex but the gist is that there is something called the policy function. The policy function is what makes it so that you don\u2019t need millions of examples, just a few will do. You can imagine this to be like a mixture water and oil. And then you do something that forces the water and oil to unmix and you get the oil to move to the top of the water. So, the model now learns that your prompt/question should be followed up things relevant to that question. In short, it has learned how answer a question, which is not trivial.\u00a0\nAfterwards, you might apply something called dropout, when you only update some of the weights so that the models retains most of its memory while at the same time learning new things.\u00a0\nFinally, they utilize one-shot learning, which is when you create and fine tune a second neural network (although you can potentially use the original neural network before applying drop out). Essentially, two neural networks are competing for getting the correct answer and of course, the incorrect one is punished. In addition there is another neural network that analyzes the output of both networks and gives them a reliability score. The reliability score is hidden somewhere in the neural network and helps the overall AI learn new information without having to modify the original weights, which might now be super sensitive.\nThe problem Google has is that it\u2019s a profit company, so they have to pay for all the training data or risk getting sued. OpenAI was a nonprofit so they could use it all for essentially free and if there ever was a lawsuit, they could argue that they don\u2019t have money and that their work is for the benefit of society.\u00a0",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716616200,
    "created_utc": 1716616200,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l5ktvdi",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1czhvac",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l5ktvdi",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l5igq1o",
    "permalink": "/r/ChatGPT/comments/1czhvac/google_doesnt_seem_to_be_able_to_get_llms_right/l5ktvdi/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716616215,
    "saved": false,
    "score": 3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 3,
    "user_reports": []
}