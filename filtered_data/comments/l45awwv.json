{
    "_meta": {
        "retrieved_2nd_on": 1715905720
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "coldnebo",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_5ckjm",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "to answer specifically about your research questions:\n\nLLMs are essentially search engines for concepts like Google was a search engine for words. This is a difficult nuance to grasp even for experts in AI because being able to search on a concept is a level of abstraction and integration higher than words alone. \n\nKorzybski thought that meaning was not contained within words intrinsically, but in the relationship networks between words. Tokenization in LLMs literally extracts relationship networks by codifying what words will be near to other words within hundreds of thousands of words. I think this is exactly what Korzybski was talking about in his book \u201cGeneral Semantics\u201d. I think this is what gives LLMs their power right now. People are falsely attributing that power to reasoning and intelligence, but I think \u201cstochastic parrot in concepts\u201d rather than in words is a more accurate summary of the current state of the art.\n\nNow if you look at this like a scientist you just see a tool and an interesting set of facts that can lead to surprising behavior. It\u2019s not a religious experience, but we can use this. \n\nIn particular people have been getting traction in areas where accuracy is needed by combining LLMs with other technologies. For example, the prompt might be to design a query for Wolfram Alpha and then describe the results of that query. This approach is less vulnerable to hallucination because we are treating the LLM as a text processor not as an expert in something.\n\nThe current experiments along these lines involve layers of prompts integrated with trusted sources to pull together something that works. But there\u2019s still a lot of tinkering and guesswork involved.\n\nAI is like an undergrad research assistant who will enthusiastically throw themselves into the problem at hand and will come back with a bunch of stuff without knowing what any of it means. A graduate would filter that to the relevant information, and an expert would perhaps find the nugget of gold hidden in the dirt\u2014 a correlation that when investigated and refined yields new insight.\n\nSo I think AI is reasonably good at getting a large survey of things from a new topic. But the hard part of science, collecting and vetting the data for accuracy\u2014 that still requires a human touch.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1715776111,
    "created_utc": 1715776111,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l45awwv",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1csdsfg",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l45awwv",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l44tujq",
    "permalink": "/r/ChatGPT/comments/1csdsfg/chatgpt_is_the_most_amazing_invention_and_i_cant/l45awwv/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1715776126,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}