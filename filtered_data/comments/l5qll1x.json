{
    "_meta": {
        "retrieved_2nd_on": 1716857631
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Virtamancer",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_kvniqgt7",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "> Please explain what you mean by \"shitting on how the models work.\" \n\nI already did. I don't care if theory shows that it doesn't know anything, least of all what it's doing or what the things mean that its telling me. All I care about is that, by some magic, the practical reality is that it's incredibly effective *despite these shortcomings*.\n\n> The fact that you automatically reject any take which disagrees with yours is not an insult to me. It just shows your cognitive limitations and lack of critical thinking.\n\nUsing my cognitive faculties and employing critical thinking to arrive at a conclusion is the opposite of \"showing cognitive limitations and lack of critical thinking\". Your view assumes that I've jumped to a conclusion, which ironically speaks more to your own cognitive limitations. As I pointed out, I've arrived at a perspective by actually using the things as tutors in the real world.\n\n> No one told you that \"it's dumb\" - that's all you could derive from it with your black and white thinking.\n\nQuit being so hostile and dismissive, that's you projecting again. By \"dumb\" I was referring to your way to pointing out that it doesn't actually know things. That's a very good example of \"dumb\". A dumb phone or a dumb pipe also use the word \"dumb\" to convey that the tools, while helpful, have limitations.\n\nAgain, my point was that the limitation of whether it knows what it's telling you or whether it knows whether that information is true is irrelevant\u2014because in actual use it's *effective*.\n\n> I have no idea what \"complaints about its tutoring style\" you're talking about\n\nThis is becoming a trend......... try to read my post again.\n\n> It can mimic certain reactions, it can be encouraging, it's obviously very patient, but it's not yet capable of actually knowing and understanding you.\n\nNobody cares. It's effective.\n\n> all it can do is generate some banal, generic insights.\n\nWildly, objectively false.\n\n> Prompting it for a particular style means you only get what you think you need, while a human being can challenge you in ways you haven't thought about.\n\nPrompting it for a better output forces you to reconsider what you actually want to be asking for, which is precisely the sort of cognitive exercise that makes interactive learning effective.\n\n> while a human being can challenge you in ways you haven't thought about.\n\nThis is the essence of my disagreement with you. LLMs just flat out *can* challenge you to think more effectively, in out of the box ways or ways you haven't considered\u2014not simply for the sake of the challenge, but because they're capable of identifying why you'd ask such a dumb question. On the other hand, literal teachers and *especially* tutors, when I ask them an out of the box question, straight up half the time they just dont' know the answer, and the other half they want to tell me \"don't do that, just do this instead\". But the reason I'm asking how to do X is because I need to see whether Y is truly a better thing to do from experience, so I can have experience with not only learning to identify better ways of doing things from worse ways, but so I can personally judge whether the people around me are competent (quite often they are competent). Teachers don't have time to tackle problems from unique angles, and tutors often just know how to solve problems the way they learned so when you ask them how to do it the way your textbook teachers they frequently are unable to.\n\nChatGPT on the other hand, when I ask a stupid question, it literally says something like \"oh, I see why this stupid question is reasonable, because you're thinking more about <thing I'm thinking about>\". It will answer my question not only correctly, and without reservation, but it will do so eagerly and in an encouraging way. THEN it will tell me \"but really, most people do X, Y, and Z because blah blah blah.\" And THAT is insanely helpful. That, in addition to the fact that it just knows random obscure technical details that tutors and teachers are constantly wrong about or have forgotten.\n\nAdditionally, a HUGE part of asking for help with something is when you can't verbalize what you're asking for\u2014you don't know what you don't know. ChatGPT is a language model so almost without fail it understands what you're meaning to ask. Human tutors are extremely bad at this.\n\nGod bless tutors, by the way. Truly they're special treasures. But they, much more than ChatGPT, have limitations that detract from the tutoring experience. ChatGPT is almost optimized to replace them in every aspect; it's actually shocking how backwards your take is on every point, which suggests you maybe just don't use the LLMs for tutoring and have limited RECENT experience with them.\n\nOne final point, is on the topic of the LLM giving bad information:\n\n> The problem is that until these problems are fixed, there is a degree of unreliability which makes them risky - and particularly to a novice who can't spot the errors as effectively as a specialist.\n\nA novice LLM user is only one for a short period. You VERY quickly (like, within a few tens of prompts) begin to be able to identify where the thing is hallucinating. The only people who complain about this have been AI-haters in my own personal life (often, teachers) who don't use them. Googling also has the same problem, but way worse because you have to sift through a mountain of shit to find a POTENTIALLY useful answer\u2014whereas the LLM may just flat out lie to you and it's obvious because you've seen the pattern before, so you adapt the prompt to get a correct answer. Like googling became a necessary skill, so will prompting. The solution is not to hide from it, but to learn how to do it effectively.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716728020,
    "created_utc": 1716728020,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l5qll1x",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d0mcpn",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l5qll1x",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l5p8uvn",
    "permalink": "/r/ChatGPT/comments/1d0mcpn/is_private_tutoring_going_to_disappear_soon/l5qll1x/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716728035,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}