{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1714187325
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "terrible_idea_dude",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_8cnfnva0",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "I think my main issue is just in the usefulness of the term AGI as a distinct category -- we both can agree that LLMs are remarkably powerful and have unprecedented general knowledge and ability.\n\nI can easily imagine a GPT-5 which improves its spacial reasoning without being very different from GPT-4.  Would that be AGI then?  Is there really THAT much of a meaningful difference between our current LLMs and a future LLM that can count the marbles in the jar correctly?\n\nI think the main reason that I call LLMs AGI is that, before transformers and LLMs and GPT, the best, most cutting edge AIs, were incredibly specialized.  Probably the only one that came close was Watson, and literally the only thing it was able to do was answer very hyper-specifically formatted factual questions.  Then, suddenly within 5 years of the invention of the LLM, we have AIs that can beat humans at *practically any task that can be described in text*, from creative, emotional, factual, logical, almost any kind of reasoning you can think of given the medium, and that's before the multimodal upgrades!\n\nTo me this is such a jump in capabilities, from <1% of tasks to >90% of tasks, that I feel entirely comfortable putting LLMs in the \"General Intelligence\" class of AIs, because the scope of things they can do is so great and so general that they are far closer to even the most utopian, strict categories of \"AGI\" than anything that has ever come before them.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714057718,
    "created_utc": 1714057718,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l17lp2q",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1c9ofxj",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l17lp2q",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l17f5wq",
    "permalink": "/r/ChatGPT/comments/1c9ofxj/even_people_who_follow_ai_dont_really_understand/l17lp2q/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714057735,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}