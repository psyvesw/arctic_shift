{
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Wollff",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_4kqj1",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": ">That wasn't my argument\u00a0\n\nNo, that was your argument. It's what you said. I asked: \"What the fuck do you consider intelligent then?\"\n\nAnd you answered with \"something that understands you correctly\". And then you proceded that something which inconsistently replies to a prompt, is \"not really intelligent\".\n\nThat's obviously nonsense, because a 4 year old which inconsistenly replies to your prompts toward doing differential equations, is at least somewhat intelligent. Even when the little one is overwhelmed by differntial equations, doesn't understand the prompt, and responds with drawing kittens, dogs, and reciting the alphabet.\n\nSo of course you were talking nonsense there. But that was your argument. It was what you said.\n\nIf what you said is not what you meant, that's not me misunderstanding you, or making a strawman. It's just you saying something you didn't mean. That's not on me.\n\n>And does it differently every single time, then they don't get the task\n\nGreat. So do LLMs do that? Ask it to draw a picture of a cat 100 times in a row, and get back to me with your results. If it's a cat all the time, that is a clear result.\n\nIf the outcome of this experiment is as I expect, we can conclude that, by your original definition, the LLM \"gets the task\", and by extension it's intelligent. Glad we could clear that up.\n\n>Intelligence requires understanding the task and the intent to achieve it. LLM lacks both.\n\nJust to be entirely clear: You are moving the goalposts now.\n\nYou didn't clarify that intelligence requires the intent to \"achieve the task\", or that intelligence requires \"understanding the task\". The whole concept of intelligence being necessarily \"task based\" is something you just brought up now. It's also obvious nonsense, but it's new nonsense. It's a moved goalpost, as none of that was in your original argument.\n\nAnyway, that's a bold claim. I can claim the same about you. You don't understand this text. You are just a neuronal machine which doesn't really meaningfully understand what you are replying to. You also don't have the intent to achieve anything by writing this. You are not really intelligent.\n\nCan you prove to me that you really understand this text, and are not just following patterns? If you are doing better than an LLM, that says nothing. You just follow the patterns you learned better than an LLM. We can't just go by the outcome.\n\nThat's a claim I can make. Can you disprove it?\n\nIf you can't, then we have a bit of a problem. Because if that claim in regard to you can't be disproven, it can't be disproven in regard to LLMs either. And non disprovable claims are the stuff that is beyond empirical inquiry. With that line of argument, we are moving into the realm of pure faith.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1717331396,
    "created_utc": 1717331396,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6rbeeq",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d61qvl",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6rbeeq",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l6r2uxt",
    "permalink": "/r/ChatGPT/comments/1d61qvl/anyone_else_feel_like_theyre_going_crazy/l6rbeeq/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717331413,
    "saved": false,
    "score": 1,
    "score_hidden": true,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}