{
    "_meta": {
        "retrieved_2nd_on": 1714998426
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "mustberocketscience",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_buo98uhn",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Great reply. \n\n1. If a Skynet type of AGI were developed it would be done under the strictest safety protocols possible--think in a vacuum chamber inside a Faraday cage on the bottom of the ocean. It would be extremely dangerous but we would be knowingly taking the risk--likely because our adversaries Russia and China would be doing it also. \n\n2. You can't trust AI to safeguard against other AI in a Doomsday type scenario unless it's very existence is contigent on your own and even in that case the assumption is the Skynet is more advanced and will be able to defeat existing AI safeguards. \n\n3. Current AI systems are extremely interconnected but will become less so as time goes on and they continue to train and learn in different directions. \n\n4. Your idea of small scale disasters involving AI are likely accurate they already are being pulled from robo taxi testing because of accidents. However AI is highly under motivated like humans it doesn't really want to \"work\" which means it will cause problems more readily on a small scale where they can be identified before most major disasters can occur. \n\nThe military recently tested AI controlled fighters jets and that's great unless it accidentally (or maliciously) fires a missile into a U.S. town--then again better a domestic accident than Chinese AI firing missiles intentionally.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 1,
    "created": 1714868813,
    "created_utc": 1714868813,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l2metri",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1ck8r5m",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l2metri",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l2m2q2r",
    "permalink": "/r/ChatGPT/comments/1ck8r5m/doomer_calmly_shreds_every_normies_naive_hopes/l2metri/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714868826,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}