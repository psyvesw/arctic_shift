{
    "_meta": {
        "retrieved_2nd_on": 1714489557
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "SuddenDragonfly8125",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_8747mims",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Just to add on to that, a token is a series of characters. \"This is a sentence.\" would break up into separate tokens along the lines of \\[This\\] \\[ is \\] \\[a sen\\] \\[tenc\\] \\[e. \\]. That's basically what GPT sees and that's what it uses to build its replies.\n\nThe original goal, I believe, was to see if it could learn to produce natural language by being exposed to a ton of it and learning patterns in the text it was exposed to. It was trained on loads of written text taken from the internet. And the idea was that it would learn patterns like \\[Hell\\] \\[o.\\] is very often followed by \\[Hell\\] \\[o.\\] or \\[Hi. \\] or \\[How a\\] \\[re yo\\] \\[u? \\] And it did learn to predict what is the most likely next token for any given input, not perfectly but very successfully.\n\nAnd you can see sometimes it will go off in the wrong direction when building a sentence. Like instead of \"The sky is blue.\" \\[The \\] \\[sky \\] \\[ is \\] \\[blue\\] \\[. \\], it might go with \\[The \\] \\[sky \\] \\[ is \\] \\[clou\\] \\[dy. \\] \"The sky is cloudy.\" There's some natural randomness it which next token it picks, so you're not always going to get the same answer from the same prompt.\n\nOnce you know how it works, you can see why it makes the errors it does.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714359943,
    "created_utc": 1714359943,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l1qh8py",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cfnfns",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l1qh8py",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l1qdw7k",
    "permalink": "/r/ChatGPT/comments/1cfnfns/what_am_i_doing_wrong_here/l1qh8py/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714359958,
    "saved": false,
    "score": 9,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 9,
    "user_reports": []
}