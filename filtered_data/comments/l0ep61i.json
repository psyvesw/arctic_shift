{
    "_meta": {
        "removal_type": "removed",
        "retrieved_2nd_on": 1713720822,
        "was_deleted_later": true
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "ObjectivelyCorrect2",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_8k6yrw6t",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Well yeah. It's amoral wokism pervading a new technology. Perverting the paradigms an ai can use severely limits its utility to humanity. What if one day neural networks get to the point they can more accurately speculate theoretical models than humans can, but is limited because its weighting is taking into account inconsequential niceties like a 2024 leftist's interpretation of what is important in the output of a dataset.\n\nLike let's pretend I'm some student who has a theory the increase in violent crime in an area is due to a food additive that only interacts with a gene that predisposes someone to violence that's more commonly found in black people. In order to trawl said data without a team and sufficient funding requires ai to not be subservient to a leftist's false moral intuitions.\n\n\"Sorry but I can't do that because race science is bad :(\" (even though this example wouldn't be), \"Sorry but I can't do that because we've predetermined the cause of black people committing violent crime is socio economic in nature\".\n\nWe will literally not stop bringing it up because it's a bad and immoral paradigm implemented by low iq activists whose decision making power should be returned to the domain of making coffee for their betters.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 1,
    "created": 1713591216,
    "created_utc": 1713591216,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l0ep61i",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1c81qya",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l0ep61i",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l0dfz2u",
    "permalink": "/r/ChatGPT/comments/1c81qya/ai_from_meta_falls_short_on_inclusivity_assessment/l0ep61i/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1713591233,
    "saved": false,
    "score": -3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": -3,
    "user_reports": []
}