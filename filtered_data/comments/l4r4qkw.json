{
    "_meta": {
        "retrieved_2nd_on": 1716265744
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "chinawcswing",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_3bdif8p",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "You can learn to build a bioweapon or manufacture methamphetamine from Google or from buying books. Should we add safety features to Google and to books in order to stop people from learning how to manufacture bioweapons or meth? \n\n> In fact I\u2019d like the LLM to be clever enough to know if the person is trying to do that, even if the person is very clever about it \n\nWow, that is just scary. Anyone who takes a scientific interest in biology or chemistry, or even an outright scientific interest in bioweapons, could be prevented from using ChatGPT to learn about these things because of safety fanatics like you.\n\nYou say you are not in favor of banning speech, but also say you want some kind of safety mechanism to prevent ChatGPT from writing about topics you find scary. \n\nWhat is the exact mechanism you are proposing here, if not government intervention? Do you want Sam Altman to self-regulate? What are you going to do if he decides to abandon self regulation?\n\n> We also have deep fakes which are hugely concerning. A really good deepfake of a world leader announcing a nuclear strike could be quite catastrophic if other people believe it\u2019s genuine.\n\nDeepfakes are already good enough to do this. Everyone knows this. If there was a deepfake of Biden saying he wanted to nuke China, Xi Jinping will of course double check the veracity of it without responding.\n\nI hope you realize that there are opensource LLMs available today that are completely unregulated and never can be regulated. You can create deepfakes and ask for instructions to create bioweapons from a local LLM that you can run in the cloud. \n\nEven if you safety fanatics succeed in crying to the government for these useless and dangerous safety regulations on GhatGPT, you will never be able to regulate open source LLMs.\n\nWhat is the point in having regulations on ChatGPT but not on open source LLMs?",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716136135,
    "created_utc": 1716136135,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l4r4qkw",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cuam3x",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l4r4qkw",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l4qvps7",
    "permalink": "/r/ChatGPT/comments/1cuam3x/openais_head_of_alignment_quit_saying_safety/l4r4qkw/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716136151,
    "saved": false,
    "score": 0,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 0,
    "user_reports": []
}