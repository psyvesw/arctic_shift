{
    "_meta": {
        "retrieved_2nd_on": 1716334016
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Zaki_1052_",
    "author_flair_background_color": "#46d160",
    "author_flair_css_class": null,
    "author_flair_richtext": [
        {
            "e": "text",
            "t": "I For One Welcome Our New AI Overlords \ud83e\udee1"
        }
    ],
    "author_flair_template_id": "a89b1af6-ada4-11ed-949a-0eb08cc0f913",
    "author_flair_text": "I For One Welcome Our New AI Overlords \ud83e\udee1",
    "author_flair_text_color": "dark",
    "author_flair_type": "richtext",
    "author_fullname": "t2_lx6lk2a1",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "(*Cross-commented from r/ClaudeAI for visibility*)\n\nFirst of all, I\u2019d just like to thank you for your work here. This kind of indie research \u2014 that is useful, methodical, and reproducible \u2014 is exactly what I frequent these subs for. Given that it was so easily reproduced, I\u2019d like to share what I was able to get from the API. This was truly a fascinating experiment!\n\nI\u2019ll share the links to the PDFs of the Chat History I got from 4o \u2014 tested twice, and the second time, I allowed it to do them one by one and check its answers; and from Claude Opus \u2014 also via API, but it is pretty expensive, so I only tested it once.\n\nI found that the performance for GPT-4o was definitely far better than what you got with the web UI, though still disappointing \u2014 at first. The main thing that I noticed was simply that it seems to have gotten\u2026well, not to personify the 4o model any further than it already has, but for lack of a better word\u2026tired? \n\nThis may be a product of the context window, but in the first Proof for GPT-4o, when asked to do all the articles at once, it did the first two mostly correctly, and then seems to have just given up for the last 2. I believe that its attention mechanisms simply can\u2019t sustain a ratio of input to output tokens over a single response. \n\nI didn\u2019t want to sabotage things for a pure test like that, so I let it be, but in the second test, I allowed it to spread out its responses over multiple requests, and then summarize its final answer, and I do believe it got them all right! I actually had to double-check that I didn\u2019t accidentally give it the answers! Here\u2019s what it said: \n```\nSummary\n\t\u2022\tArticle 1:\n\t1.\tLiteracy rate of Valmoria\n\t2.\tPopulation of Insularia\n\t3.\tMain exports of Zantoria\n\t\u2022\tArticle 2:\n\t1.\tPopulation of Meridonia and Zantoria\n\t2.\tPopulation and area of Nordavia and Valmoria\n\t3.\tGovernment type of Montania\n\t\u2022\tArticle 3:\n\t1.\tGovernment type of Valmoria\n\t2.\tCurrency of Estavaria\n\t3.\tClimate description of Insularia\n\t\u2022\tArticle 4:\n\t1.\tPopulation of Nordavia\n\t2.\tClimate description of Montania\n\t3.\tPopulation and area of Arcadia\n```\nInterestingly, Claude Opus hallucinated BADLY at first (to the point that I went into my console to check whether I selected the wrong model). But, oddly, when given the adjacently-ToT (tree of thought) prompt that I gave to GPT, it seems to have corrected itself (given the hint of 3). \n\nWithout that additional guidance (and it only seemed fair), I would have been **extremely** disappointed in it. But, it seems to have recovered alright. It didn\u2019t categorize them like GPT did, and it\u2019s 4am for me so I\u2019m not thinking about this myself, but it looks like it got most of them!\n\nHere\u2019s the Drive link to the files; please let me know what you think! I didn\u2019t test Mistral, as if Opus (which is usually my favorite after 4o) did so badly on its own, I don\u2019t think they have any chance. I\u2019d be willing for science though! Thanks again! Link: https://drive.google.com/drive/folders/1GXMqUrvR_WeKwUfcLFRwoMXtyK0MRMXd?usp=sharing\n\nEdit: I did have extra pre-prompting in my system, but I use it for everything, and it didn\u2019t seem right to exclude it; at a baseline, I would always include those instructions when using the API, so it seemed fair to use them here (I definitely didn\u2019t forget to remove them, lol).\n\nFinally, before I forget and leave this (I need to study for my Calculus final in a few hours), this is the GitHub repo I use for the API so you can see there isn\u2019t anything sketchy about how I interact with it. Temperature is a baseline of 1, and ChatHistory takes the conversation as expected and formats everything into an HTML export (I used the `task` [branch instructions](https://github.com/Zaki-1052/GPTPortal/blob/task/public/instructions.md) with the prompt you provided): https://github.com/Zaki-1052/GPTPortal",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716204409,
    "created_utc": 1716204409,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l4uzzae",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cvmnt5",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l4uzzae",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1cvmnt5",
    "permalink": "/r/ChatGPT/comments/1cvmnt5/attention_is_all_you_should_need_a_benchmark_of/l4uzzae/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716204425,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}