{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1715094165
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "SupportQuery",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_f6yhw7j2i",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": ">  all chatgpt does is predict the next word\n\nThis is true. However, in order to predict the next word *correctly*, it has to actually acquire something we'd call *understanding* -- it has internal models of the world, some representation of concepts like \"tower\", \"queen\", \"hot\", \"falling\", \"laugh\", etc. -- without which it couldn't predict the correct the correct words to follow your question.\n\nHow it actually does this is *unknown*.\n\nThe founder of OpenAI (ChatGTP): \"we do not understand how they work\" (https://arstechnica.com/information-technology/2023/05/openai-peeks-into-the-black-box-of-neural-networks-with-new-research/).\n\n\"Our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces.\"\n-- *The unreasonable effectiveness of deep learning in artificial intelligence*, Proceedings of the National Academy of Science 2020\n\nAnyone waving their hand dismissively saying \"it *just* does X\", as if they know how it works, needs so step up and claim their Nobel prize. [This guy tried to reverse engineer a 400 parameter model that adds two numbers](https://cprimozic.net/blog/reverse-engineering-a-small-neural-network/), and the way it was adding is fucking *insane* (converting numbers to sin waves, summing them, distorting them to flatting them to a square wave, using a digital-to-audio converter to read the result back out).  We have no idea how a *trillion* parameter model can recognize a human smirk. It's completely inscrutable to us.\n\nAgain, we don't really know how they work any more than we know how brains work, despite knowing that brains are made of (neurons, synapses, etc.). Yes, neural nets are just statistics, but so too may be your brain.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714964555,
    "created_utc": 1714964555,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l2s2yov",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1ckzg9j",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l2s2yov",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1ckzg9j",
    "permalink": "/r/ChatGPT/comments/1ckzg9j/i_hate_how_people_downplay_chatgpt/l2s2yov/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714964570,
    "saved": false,
    "score": 117,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 117,
    "user_reports": []
}