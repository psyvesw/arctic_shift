{
    "_meta": {
        "retrieved_2nd_on": 1713377229
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Loknar42",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_2ssxttzu",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "As far as I can tell, you cannot run ChatGPT locally. It is a proprietary and highly guarded secret. All fine-tuning must go through OpenAI's API, so ChatGPT stays behind its security layers. My guess is that you do not understand what is required to actually fine-tune ChatGPT. Look at the documentation [here](https://platform.openai.com/docs/guides/fine-tuning). In particular, look at the examples provided to get a sense for how you need to prepare the training data. The fine-tuning API does not support ingesting raw PDF or DOCX files. You need to craft prompt/response pairs from your raw data to feed to the API. So you need to know what kinds of prompts end users will try in order to access your data, and then you need to provide the actual data from the PDFs in a sample response for ChatGPT to learn. Preparing this training data is a massive amount of laborious human busywork. If you thought that ChatGPT will just read your PDFs and learn them, that is not how fine-tuning works.\n\nRight now, this idea of: \"I provide a pile of raw data, and ChatGPT gives me an intelligent interface to that data\" isn't quite here yet, at least not in any kind of plug-n-play sense. It would probably actually be more effective to include your raw data in a *pre-training* run of GPT, alongside all the other raw data, but as far as I can tell, OpenAI does not provide this level of access. Most likely, this is a very compute-intensive process anyway, which is probably why it is not exposed/monetized (most users would have an aneurysm when they saw how much it costs). So you are left with hacks, kludges, and all other manner of workarounds to get the results you want.\n\nInstead of asking: \"How do I optimize cost?\" you should be asking: \"How do I actually solve this problem?\" I don't think you're there yet.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1713246761,
    "created_utc": 1713246761,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "kzsj60n",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1c53sko",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_kzsj60n",
    "no_follow": false,
    "num_reports": null,
    "parent_id": "t3_1c53sko",
    "permalink": "/r/ChatGPT/comments/1c53sko/finetuning_100gb_of_documents_how_to_minimize_cost/kzsj60n/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1713246778,
    "saved": false,
    "score": 3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 3,
    "user_reports": []
}