{
    "_meta": {
        "retrieved_2nd_on": 1716868823
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Virtamancer",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_kvniqgt7",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "All these corporations would love to usher in nuclear jihad if it was their optimal strategy towards monopoly, that's the one truth we know about capitalism that doesn't rely on conspiratorial thinking.\n\nAlso, I wouldn't be so quick to expect that the models are not intentionally hamstrung. Keep in mind, gpt4 was finished training 8 months before the general public knew about it, which means it was already done before gpt3 was even released. Then they spent 6 full months lobotomizing it; this isn't conspiracy either, OpenAI at the time were going around bragging how they spent 6 months making sure it couldn't answer certain types of questions that its training data empowered it to answer. That was 2 years ago and they've made massive progress since then, god only knows what their internal models are capable of that we won't even hear about a gimped version of for another 8 months. And Google is known for having internal models that they're developing for businesses expressly designed for doing chemistry research, which a focus on pharmaceuticals.\n\nMy point is just that the models are probably capable of doing chemistry about as well as programming (and they can do programming better than the models the public has, which have been crippled through safety tuning), but the best training data towards those ends are likely reserved for their internal models for pharma corporations etc.\n\nAs for the so-called safety stuff, I just what I would call a more down-to-earth view: \"safety\" means protecting their monopolistic interests, so it's always going to be centered around influencing government to make laws that favor them over the general public, influencing culture with diversity propaganda (because that's what benefits multinational corporations), and stringing along consumers so there's always the next new product. None of this will ever make people more independent, that's the antithesis of what profit-seeking corporations or governments require.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716739209,
    "created_utc": 1716739209,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l5rcszc",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d0mcpn",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l5rcszc",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l5r9dpm",
    "permalink": "/r/ChatGPT/comments/1d0mcpn/is_private_tutoring_going_to_disappear_soon/l5rcszc/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716739226,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}