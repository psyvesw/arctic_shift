{
    "_meta": {
        "retrieved_2nd_on": 1716164632
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "MtMcK",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_hkkxse7",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "So, I guess you really are that dumb then. The dangers of ai don't actually have anything to do with the ai itself, it's not going to come alive or anything, but rather, the dangers are in how it will affect society and drive changes in the way we live, work, socialize, and communicate. We're already seeing jobs being deleted because ai is cheaper, we're seeing companies switching from human artwork to ai junk, we're already seeing enormous, world-changing effects in how people gain information, work, and create, even though we're still at the most basic level of ai, so it should be very obvious that if ai isn't carefully managed and regulated, it WILL have disastrous impacts to human society, culture, and relationships. It's not a matter of whether you, personally, can learn how it works, but if humanity as a whole will be able to learn how it works, understand it, and then control it in a way that benefits us, rather than end up destroying the societies we've built because a couple of companies decided \"innovation\" and money is more important than making sure ai doesn't destroy our already-fragile society. I mean, we're already on the precipice of a near-irreversible wealth gap, total surveillance states, and crackdown in every form of protesting and resistance, and ai has so far proven to exacerbate those problems, not fix them, so I'd say that safety measures and regulation are pretty much mandatory to prevent total disaster.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 1,
    "created": 1716035024,
    "created_utc": 1716035024,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l4law60",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1curhln",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l4law60",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l4l9juc",
    "permalink": "/r/ChatGPT/comments/1curhln/why_are_openais_top_safety_researchers_quitting/l4law60/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716035038,
    "saved": false,
    "score": 3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 3,
    "user_reports": []
}