{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1715807824
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "TheRealStepBot",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_wv3r1",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Yes\n\nBut mostly because simulation and p zombies. \n\nSearle was wrong (duh) about his Chinese room. The thought experiment is great, the conclusion just woefully missed the mark. If anything it proves precisely the opposite of what Searle claims it does but that\u2019s because searle made the same mistake as the commenter I\u2019m replying to.\n\nSearle though that the thought experiment showed how computers can never be shown to think even if they did look like they were, but the real takeaway message is that assuming each one of us is a Chinese room (or English or Swahili or multilingual room) there really is absolutely no way to tell that we aren\u2019t just biological simulations of actual thinking people. We only treat each other like thinking individuals out of common courtesy, not any real proof that anyone is actually thinking.\n\nThere is nothing special about the person in the room or computers. They are arbitrary descriptivist system boundaries drawn on reality, not reality itself. There is no room there is no computer. There are just groups of atoms doing atom things. Self referentially of course there are no atoms just groups of subatomic particles doing their thing. \n\nYou can always describe the world with whatever arbitrary system boundaries you want. They are not special except by agreement for the purpose of increasing information transfer rates. \n\nIt\u2019s best that we treat Ai like they can think not because it matters whether they can or not, but because of the moral good of doing so realized within ourselves by doing so.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1715678214,
    "created_utc": 1715678214,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l3z6v7i",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cr6go9",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l3z6v7i",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l3z4zsg",
    "permalink": "/r/ChatGPT/comments/1cr6go9/something_rubbed_me_the_wrong_way_about_todays/l3z6v7i/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1715678230,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}