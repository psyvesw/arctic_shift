{
    "_meta": {
        "retrieved_2nd_on": 1717360791
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "bobzzby",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_mpfoyki",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Every society in history has viewed the brain as functioning like their current mode of technology. Enlightenment thought of it as like a watch/gears. Industrial society viewed the brain as hydraulic etc. The brain isn't like any of these things and it's sure as hell nothing like a computer. It uses quantum effects, neurotransmitters, microtubules, has a microbiome and also functions at the level of complex systems of electrical waves. We've also just discovered that jellyfish without a brain can learn so consciousness is arguably not even a feature exclusively caused by brains. Slime mould can self organise to solves mazes. The boquila trifoliolata plant can imitate leaf shapes of other plants around it, including plastic plants. Noone knows how. Philosophy of science is moving towards the idea of a conscious universe. And you're telling me that an LLM, Basically a crude text prediction engine running on logic gates will develop \"general intelligence\". We are a million years away from understanding intelligence or consciousness. There is also the problem of politics and how it would be implemented even if we could do it. MURDOCH'S newscorp has now started working with AI systems so good luck using it for anything other than top down class warfare.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 1,
    "created": 1717231183,
    "created_utc": 1717231183,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6lk06d",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d5haqv",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6lk06d",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l6lj8rv",
    "permalink": "/r/ChatGPT/comments/1d5haqv/anthropics_chief_of_staff_thinks_agi_is_almost/l6lk06d/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717231198,
    "saved": false,
    "score": 10,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 10,
    "user_reports": []
}