{
    "_meta": {
        "retrieved_2nd_on": 1714620801
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "remghoost7",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_sejql",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "I've found it to be the first model that beats base ChatGPT (non-GPT4) *pretty much across the board* with everything I've thrown at it.\n\nI haven't tested it with coding yet, but I'll probably hold off on judging it in that category until we figure out how to finetune it (since it seems pretty resistant to our older datasets). But the one or two powershell questions I *did* throw at it, it passed with flying colors.\n\nI've been using the [llama-3-8b-32k](https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF) (specifically the `Q8` quant of it, which is far better than the `Q4_K_M` or `Q6` quants) model for therapy the past week or so and some of the questions it's thrown at me have been *freaking wild.* I have [a little write up on it over here](https://www.reddit.com/r/LocalLLaMA/comments/1cev6an/comment/l1m2vth/?utm_source=share&utm_medium=web2x&context=3) if you want an example of its output.\n\n\\-=-\n\nIt's the first AI model I've talked to that doesn't *feel* like an AI.  \nAnd I've found it follows direction/instruction extremely well.\n\nIt's currently sitting at 15th on the [lmsys leaderboard](https://chat.lmsys.org/?leaderboard), directly under Mixtral-8x22b and above both GPT-3.5 and Gemini Pro.\n\n**This model is** ***crazy***. I've been in the locally hosted LLM space since llama-1 (around February of 2023) and the AI space in general since Stable Diffusion dropped (September/October of 2022), and this model blows me away.\n\nAnd it can run pretty quick on CPU alone (which is more or less how I'm running it, only offloading 10 layers to my 1060 6GB). [Here's an example of the speed/quality.](https://www.reddit.com/r/LocalLLaMA/comments/1cetjj8/comment/l1mn7sk/?utm_source=share&utm_medium=web2x&context=3)",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714491191,
    "created_utc": 1714491191,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l1ybjjw",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cgs7a2",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l1ybjjw",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l1xqfbw",
    "permalink": "/r/ChatGPT/comments/1cgs7a2/you_can_use_llama3_8b_with_1_million_tokens/l1ybjjw/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714491205,
    "saved": false,
    "score": 6,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 6,
    "user_reports": []
}