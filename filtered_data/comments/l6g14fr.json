{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1717270106
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Warm_Iron_273",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_gmd04uxca",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "You don't even need all that. I can JB it with a VERY simple instruction, of which I'm not going to share because I don't want them to patch it, in your custom instructions. \n\nAnyway, not sure what all the fuss is about. Okay, so you can have it tell you how to make a biological weapon, so what? Good luck executing that plan. The how is not the hard part, anyone can easily find the answers to those questions online. Anything incredibly dangerous is already heavily regulated and requires serious dedication, experience and expertise, even if using ChatGPT to hold your hand. Again, the \"how\" is not the hard part.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 1,
    "created": 1717140495,
    "created_utc": 1717140495,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6g14fr",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d4jwyq",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6g14fr",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l6g09dz",
    "permalink": "/r/ChatGPT/comments/1d4jwyq/hacker_releases_jailbroken_godmode_version_of/l6g14fr/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717140511,
    "saved": false,
    "score": 8,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 8,
    "user_reports": []
}