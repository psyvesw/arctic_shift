{
    "_meta": {
        "retrieved_2nd_on": 1716970580
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "femio",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_ciu5n",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "What you're stating is exactly how training an AI model works. A good model should always perform well on tasks outside it's training material, otherwise it's been \"overfit\". \n\nAgain: because LLMs are only as good as the GPUs that power them and the training data given, it's not real reasoning. I work with various LLMs every single day for work - they are a fantastic tool that will change the world but just being objective, they cannot reason.\n\nBy the way, may want to check your sources. That \"novel\" research paper you're citing has been on Github since 2022. \n\n[https://github.com/diracq/qdhmc](https://github.com/diracq/qdhmc)\n\nAlso, if you read the reply, 90% of it is just \"do it the normal way but make it quantum-driven instead\" which...isn't impressive? Disclaimer, I don't work in quantum computing, but that's my impression. Either way it seems like you're buying into the hype a bit too much.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716840971,
    "created_utc": 1716840971,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l5xh9x4",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d1r1ac",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l5xh9x4",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l5xewkf",
    "permalink": "/r/ChatGPT/comments/1d1r1ac/study_finds_that_52_percent_of_chatgpt_answers_to/l5xh9x4/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716840987,
    "saved": false,
    "score": 3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 3,
    "user_reports": []
}