{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1715079765
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "hellra1zer666",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_8malnort",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "People keep repeating this because of questions like why ChatGPT can't spell backwards, why can't it calculate, so on and so forth. Because most people are very impressed with what it can do, it is just as jarring when it fails so to a seemingly simple task. The explanation for that are hallucinations, to explain those we have to bring up how an answer is inferred. There are people that call LLM nothing more than a stochastic parrot, and I'm more inclined to agree as I am to disagree, but the future of AI will not be just LLMs. We will create AIs that are truly terrifyingly intelligent and capable.\n\nI agree with you that it is an amazing feet to have a LLM trained in such a way it not only \"understands\" the intent of the question asked or the context in which the conversation takes place, but also gives a mostly fitting response. AI's are the future and will do amazing things for us as well as be used for more nefarious purposes. \n\nHaving said that, most of us who say ot \"just\" infers the next likely tokens, do not do that because we want to devalue the accomplishment or anything. The concept behind it is very simple. The truly complex tasks are the development of the topology of the model, building the \"right\" set of training data, developing tokenization and teaching algorithms that fit the model well, and choosing the right samping algorithms and put them in the right order is where an unimaginable amount of work goes into. \n\nThe idea of neurons and their weights is supposed to be simple. How the final output is calculated can be a little videos, but at least in theory you can still do that on a piece of paper (a very large paper to hold the huge matrix of each layer, the biases of the neurons, and the the algorithm of the activation function, that is \ud83d\ude05).\n\nThe black magic is the sampling algo selection, imo. Some dev somewhere enacts a truly vile ritual in some basement and asks a demon for the right sampling algos and in which order they should use them.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714950154,
    "created_utc": 1714950154,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l2r60cm",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1ckzg9j",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l2r60cm",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1ckzg9j",
    "permalink": "/r/ChatGPT/comments/1ckzg9j/i_hate_how_people_downplay_chatgpt/l2r60cm/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714950168,
    "saved": false,
    "score": -1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": -1,
    "user_reports": []
}