{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1717026439
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "vasarmilan",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_b9odplx",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Here is a paper exploring and giving proof of hidden reasoning of LLMs: [https://arxiv.org/abs/2404.15758](https://arxiv.org/abs/2404.15758)\n\n>The inner workings of an LLM is that it's an infinite narrative fractal that can simulate anyone or anything.\n\nI'll be honest, I think your understanding of LLMs is a bit simplistic.\n\nI did not however that I don't think most of these dangers come at the current GPT-4 level, which does not in most ways exceed the reasoning capabilities of most humans. But when they do, we might be in big trouble. There is a big reason why so many are researching AI alignment now, including this being the main mission of Anthropic.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1716896826,
    "created_utc": 1716896826,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l60ftpc",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d2drxu",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l60ftpc",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l60ff29",
    "permalink": "/r/ChatGPT/comments/1d2drxu/podcast_elon_musks_big_ai_contradiction_bloomberg/l60ftpc/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1716896840,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}