{
    "_meta": {
        "retrieved_2nd_on": 1715885053
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "SkinOfHotDog",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_5ffwsp0x",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Hopefully I can provide some sanity for you\n\nI work with lots of custom architectures involving optimization problems and multiple interacting queues. Many resources are handled manually including explicitly controlling threads and processes as we are often tackling low resource, high through put use cases.\n\nI had just finished my data science degree and already created some relatively rudimentary custom generative ai when chat gpt pro was launched; as such I was amongst the first large groups to use the service and have been using various models for improving coding productivity ever since. I use the models primarily for refactoring code, adding features, cleaning up readability, etc.\n\nI have had a similar experience. Overtime models are being tuned for \"better\" human reinforcement learning and provided with more methods to obtain quicker and more \"accurate\" responses while reducing hallucinations.\n\nThe result seems to be more robust towards quiz / test questions and other types of structured information; learning things that have lots of clean organized data etc. coding tasks have become much less consistent overall while gtp 3 and 4 at points have successfully improved medium level code with well crafted prompts in the past; it is more frequent that either model will provide nearly useless suggestions for anything above a hello world use case.\n\nEither model consistently gets stuck suggesting things I've instructed not to do or ignoring instructions to use a specific approach while insisting it is following instructions; 4 is much worse at this. Most ubiquitous models are almost useless for advanced coding tasks. The most effective models recently exist with the hugging face community. \n\nTo check these out easily I use lmstudio there are models tuned for coding task which generally performed better for my cases; however none of the models seem to produce code with cve security issues in mind so if you must adhere to security scans it's likely you will need to manually review your code and build environments regardless.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1715755443,
    "created_utc": 1715755443,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l44eyfm",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1crlkps",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l44eyfm",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1crlkps",
    "permalink": "/r/ChatGPT/comments/1crlkps/there_is_something_deeply_wrong_with_chatgpt_4o/l44eyfm/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1715755457,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}