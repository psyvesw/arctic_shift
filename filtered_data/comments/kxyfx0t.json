{
    "_meta": {
        "retrieved_2nd_on": 1712327903
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Loknar42",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_2ssxttzu",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "The problem you are not recognizing is that before we achieve AGI, LLMs will be a powerful tool in the hands of bad actors. Your friend didn't get the response he wanted because he was a *user*. But let's say Donald Trump wins the 2024 election, and decides that AI will help convince the population to let him be President for Life. So he nationalizes OpenAI and makes them train ChatGPT to become a Trump mouthpiece. He won't convince every American to become a Trump supporter that way, but he doesn't need to. If he convinces a clear majority, then they will handle the rest. That means capturing 25-30% of folks in the middle. That seems like a feasible goal for an LLM in the wrong but powerful hands. And if this history played out, we would almost certainly not achieve AGI, because we would be living in a fascist dictatorship whose sole purpose is to prop up a small cabal of ruling class.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1712198295,
    "created_utc": 1712198295,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "kxyfx0t",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1bus2mt",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_kxyfx0t",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_kxy2xbv",
    "permalink": "/r/ChatGPT/comments/1bus2mt/study_llms_highly_effective_at_manipulating/kxyfx0t/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1712198310,
    "saved": false,
    "score": 2,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 2,
    "user_reports": []
}