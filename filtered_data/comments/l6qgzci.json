{
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "JollyToby0220",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_aowoo3mf",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "As it turns out, data is not that important. It\u2019s actually learning that makes all the difference. There are three fundamental learning methods in AI. Supervised learning- you send in some input and correct the output. Unsupervised learning- data is split up into inputs and outputs. The inputs should generate the outputs. Reinforcement Learning- data goes in, you say its right or wrong but you don\u2019t correct the output.   \n  \n This leads to three fundamental  types of data. Labeled data (best for supervised learning), Unlabeled data (good for unsupervised learning), and synthetic data (good for fine tuning with reinforcement learning). \n\nUnlabeled data is good for pre training because it gets the AI to a point where it is usable. Labeled data is good for domain specific problems but fails terribly with unobserved data. For example, you ask the top students of every university to write an essay on some topic. Assuming every essay was great, there will be large variations in word count, structure, word usage, etc. This makes it difficult to really capture what makes an essay great, despite using state-of-the-art data. Then, you train the AI and realize the AI is biased towards its training data causing answers to be cut off, off-topic, or too short/long. With synthetic data, you let the AI generate the data. It\u2019s not important what the training data looks like, because you use reinforcement learning to update the AI. And you can actually correct it at every iteration so that there aren\u2019t knowledge gaps. This suggests that the data might not be so valuable",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1717310375,
    "created_utc": 1717310375,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6qgzci",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d636md",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6qgzci",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l6q8kii",
    "permalink": "/r/ChatGPT/comments/1d636md/godfather_of_ai_says_theres_an_expert_consensus/l6qgzci/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717310391,
    "saved": false,
    "score": 1,
    "score_hidden": true,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}