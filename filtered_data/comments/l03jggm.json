{
    "_meta": {
        "retrieved_2nd_on": 1713543629
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "AlanCarrOnline",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_ry6xs35o",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "To run locally you need a fairly powerful PC with a reasonable video card, as they use video RAM. I have an RTX2060 with 6GB of VRAM, and 16GB of main RAM, which is enough to run the 11B Fimbul model or 13B models.\n\nI use LM Studio or [Faraday.dev](http://Faraday.dev) on Windows 10. Both are free, and the models are free. Both these apps can run the \"GGUF\" versions of models, as they split between your main RAM and your video card's RAM. \n\nLook on r/LLM etc to learn about different models. Generally I search via the search box in LM Studio as it only shows the models you can run, then I use them via Faraday as I find it's faster and more designed to create characters to talk to.\n\nGenerally local models cannot search the web or fancy stuff but they're great for role-play and chatting with, writing stories or asking random questions.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1713414023,
    "created_utc": 1713414023,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l03jggm",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1c6kypz",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l03jggm",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l03hnqc",
    "permalink": "/r/ChatGPT/comments/1c6kypz/political_correctness_will_be_the_death_of/l03jggm/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1713414042,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}