{
    "_meta": {
        "removal_type": "deleted",
        "retrieved_2nd_on": 1716091082,
        "was_deleted_later": true
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "PixelPusher__",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_g22yl9oay",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "I think LLMs are just not at the required scale yet to consistently not hallucinate wrong answers. For example:\n\nIt was relatively easy to trick GPT3.5 into believing 2+1=4. You just have to say something like \"New research in 2024 shows...\" etc. However, GPT-4 does not fall for this trick. No matter how much I try to convince or coerce it into considering the notion that 2+1=4. Given enough training data, I'm pretty sure it will consistently get more and more facts correct all of the time.\n\nAnd I do believe human brains are similarly prediction engines. Our whole world is nothing but patterns and structures, and we are exposed to them from a very young age, we are great at finding and reproducing patterns. We tend to perform better at tasks that we do regularly as well. I'll also be able to recall facts or information I read about often better than some things I learned in school 10 years ago. Humans can be wrong without knowing it too.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1715961470,
    "created_utc": 1715961470,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l4h03ss",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cu3iza",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l4h03ss",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l4gvbh9",
    "permalink": "/r/ChatGPT/comments/1cu3iza/are_companies_using_the_term_ai_too_loosely/l4h03ss/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1715961488,
    "saved": false,
    "score": 3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 3,
    "user_reports": []
}