{
    "_meta": {
        "retrieved_2nd_on": 1714009406
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "AlanCarrOnline",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_ry6xs35o",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Yep. Lemme find my copy pasta... here ya go:\n\nMy go-to copy-paste for peeps unaware of local LLMs...\n\nYou need a pretty powerful PC or laptop, preferably a 'gaming' PC.\n\nThese do not do image gen. For that you need to install Stable Diffusion, a GUI for it and other types of models, and the results are awful unless you really learn and know what to do. I'd wait for SD3 to become available and tuned.\n\nSo, keeping it text-based...\n\nStep 1. Go here:\u00a0[https://lmstudio.ai](https://lmstudio.ai/)\n\nDownload the version for your operating system, which is Windows. ;)\n\nStep 2. Get to know how it works and search for and download some 'models'. typically you want a \"Q4\" or \"Q5\" version for the best balance of IQ performance versus the hardware requirements/time.\n\nMy fav is Fimbulvetr-11B-v2.Q8\\_0.gguf. I can run that on a 6GB video card with 16GB of RAM plenty fast enough. If you have less you may prefer the 7B models, some of which are censored but most aren't.\n\nStep 3. Go to\u00a0[faraday.dev](http://faraday.dev/)\u00a0and download the Windows version.\n\nI find Faraday runs faster for roleplay but LM studio is better for searching and finding models you can run (so I then run them on Faraday), and LM Studio is more technical for doing things like running your own server to connect to other services and wotnot. For general chat or role-play use Faraday, which is specially designed for that.\n\nThe apps and models are free.\n\nYou can support Faraday by running chats locally but using their paid cloud models to process.\n\nEnjoy!\n\nFAQ:\n\nIs it censored? Some models are, some are not, some are mildly censored. Even the censored ones can be tricked into going along with erotic roleplay, even with violence etc. Or just use one that isn't, such as Fimbul.\n\nIs it legal? Yep.\n\nWill it break my computer? If you install both apps and a few models it will suck up around 20-40GB of space and if you try doing much else with the PC at the same time it will be slow or even freeze. The more RAM you have the better. If it does freeze just wait, and learn that lesson. At the current time there's no great threat of malware or viruses via the steps above.\n\nCan it be really offline? Yes, I run TinyWall, which blocks everything unless expressly allowed, and both apps run entirely offline.\n\nIf it's so easy, why isn't everyone doing it? Mainly because most routes into local large language models are complicated gumpth involving knowing Python, knowing what to do with Github, installing libraries, dependencies and a heap of other bullshit. You don't need all that, just run LM studio or Faraday. So the first is people just don't know how easy it can be, the 2nd reason is you cannot do this on your phone or a basic laptop. You need a lot of hard drive space, a lot of RAM and a powerful video card with a lot of VRAM. My 5yr old gaming PC is OK for this, a newer one would be better.\n\n\u00a0",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1713879798,
    "created_utc": 1713879798,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l0vzkt7",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1cb2amn",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l0vzkt7",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l0vjk7o",
    "permalink": "/r/ChatGPT/comments/1cb2amn/is_there_any_ai_chatbot_without_any_restrictions/l0vzkt7/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1713879813,
    "saved": false,
    "score": 3,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 3,
    "user_reports": []
}