{
    "_meta": {
        "retrieved_2nd_on": 1715111839
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "trajo123",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_3ofwm7j3",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "This is going to be an unpopular opinion, but i think this line of research is pure hype. I think they picked the yoga ball to make it look more impressive than it actually is, because if the goal would have been to make the robot walk, it would have looked completely trash, especially that they hold the leash for balance corrections. I think the robot would be barely able to walk.\n\nLeaving that aside, my main gripe is with the fundamental approach: using a LLM to code up a reward function for RL. That is basically just domain expert manual coding with extra steps. You still need highly specialized prompts for the given robot. Also, making overly complex reward functions (semi) manually kind of defeats the purpose of reinforcement learning imo. Overall, using LLMs to code a reward function and then saying that GPT4 teaches a robot to do something seems disengenous, to me it looks like someone tried very hard to find some way of combining robotics with LLMs to jump on the hype train. \n\nI like the AI Explained channel and found most of the videos so far insightful and informative, but the Youtuber fell for the hype on this one, swallowed it hook line and sinker.\n\nTLDR: unpopular opinion ...it's all hype, an academic marketing gimmick",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1714982230,
    "created_utc": 1714982230,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l2sv7xx",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1clcfc9",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l2sv7xx",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1clcfc9",
    "permalink": "/r/ChatGPT/comments/1clcfc9/ai_explained_if_gpt4_can_train_a_robot_dog_better/l2sv7xx/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1714982245,
    "saved": false,
    "score": 9,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 9,
    "user_reports": []
}