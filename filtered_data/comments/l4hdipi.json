{
    "_meta": {
        "is_edited": true,
        "retrieved_2nd_on": 1716095773
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "sudo_lol",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_kd2m9rk9",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": true,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Makes sense... When GPT was made it was made, it took a month or two feeding it tons of clean accurate data. This is a very expensive process. (Lots of GPU and processing power). During this process GPT is forming its knowledge. This is called encoding (training) and is responsible for building the neural network. Much like we form pathways in our brain when we learn something. \n\nWhen we use it, i.e. type something into a prompt. Our prompt is actually encoded on the fly and passed into the neural network and a response is generated. This step is called inferencing. \n\nOne reason why we don't teach the LLM real-time, is just like our brains, if we learn something wrong it's very hard to unlearn it. Imagine if everyone who uses GPT had the ability to teach it. There would be so many bad actors \"teaching\" the LLM all sorts of false and misleading information. Another reason is its very expensive and you need to be damn sure the data you are feeding it is accurate. \n\nFor this reason and others, LLM's are only taught by the creator, and this is done at different periods in time. \n\nThere are some more steps that happen after training, but this is the gist of how and why it works the way it does.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1715966163,
    "created_utc": 1715966163,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l4hdipi",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1ct3yzg",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l4hdipi",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_l4hauci",
    "permalink": "/r/ChatGPT/comments/1ct3yzg/chatgpt4o_says_4o_doesnt_exist/l4hdipi/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1715966177,
    "saved": false,
    "score": 2,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 2,
    "user_reports": []
}