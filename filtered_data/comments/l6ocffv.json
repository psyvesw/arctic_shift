{
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "SeaDust6693",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_tdlvptnal",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "Hi. Throwaway account here because I work in EdTech and one of our products involves AI prediction/detection (Not Turnitin). The problem with these products is that not enough colleges understand how to use them. They CANNOT predict with certainty whether AI has been used. There is no evidence like you get with plagiarism. It is a prediction algorithm and should only be used as an indicator that something might be suspect. Think of it as an alarm that may have gone off in error. It should never be used as the only piece of evidence. Not to mention that using tools like Grammarly and Google Translate (if the submission language is not in one's native tongue and used to help) will skewer the score.\n\nThe problem with these products is that colleges are making them worse with their unrealistic demands. Imagine I make an AI detection product that has a false positive rate of 0.005%. Naturally this means there will false negatives too. But surely this is fairer because a much lower risk of putting students in your current situation. The problem is when testing out these products, colleges will submit ChatGPT content and if it's not detected they will claim the product doesn't work. What they want is one that will spot their ChatGPT submissions every time. Their focus is on true positives and they take their eye off the ball on false positives. This behaviour is what's driving the market. When I talk to customers and clients, I labor this point. But they want a computer to do the thinking for them.\n\nThe below tweet did the rounds last year. Note that the US has over 10x the number of college students as Australia. Ask your Conduct Hearing if they're comfortable with that number of false positives. And as others have said, ask professors to submit their own work and see how it fares. And not just one paper. The number should equal the number of student submissions. Suddenly a 0.5%-2% false positive rate won't seem so inconsequential.\n\nhttps://x.com/phillipdawson/status/1704649665055232484",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1717274541,
    "created_utc": 1717274541,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l6ocffv",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1d45xdo",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l6ocffv",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1d45xdo",
    "permalink": "/r/ChatGPT/comments/1d45xdo/falsely_accused_of_using_ai_in_college_course_how/l6ocffv/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1717274558,
    "saved": false,
    "score": 1,
    "score_hidden": true,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}