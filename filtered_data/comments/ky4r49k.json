{
    "_meta": {
        "retrieved_2nd_on": 1712440933
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "Sirisian",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_5hqm0",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "We'll keep moving goalposts with harder Turing-like tests. There are models like [PaLM-E with chain-of-thought](https://blog.research.google/2022/04/pathways-language-model-palm-scaling-to.html) and what some might look at as rudimentary thinking. There's also a large area of causal reasoning where LLMs can exhibit intuition which a lot of papers have looked into. They're not without their faults and limitations.\n\n> most people include conscious awareness in their definition\n\nHaving general purpose problem solving might be sufficient for a lot of people which is already on the same extreme. Also a little more testable if your goal is to compare against a human at least. Using either as a endpoint is fuzzy and falls into the realm of futurology. Defining where we are is still feasible, but it won't be as exact as some would like. First, we'll try to find the start, middle, and endpoints.\n\nProgrammable computing started in the 1940s with ML theory in the 1950s.\n\nRight now you can talk to LLMs like GPT-4, Claude 3 Opus, and Gemini Pro, but that's only a part of machine learning. Even the generative AI with image, video, and audio are another small part. There's also self-driving cars navigating the world in places and voice order drive-thrus that have existed for over a year. Those aren't thinking, but what we're seeing are specialized AIs. So one could say we're at a point with many specialized models on fragmented datasets with various specialized abilities. The big picture is to notice how close a lot of these advances are to right now.\n\nFrom a futurology point of view one would use the singularity as the end \"point\" which is 2045-2100. Essentially there are a lot of trends across various fields, not just in machine learning, all improving and feeding back into one another. You'll notice these in the form of [breakthroughs in cross-disciplinary fields](https://blogs.microsoft.com/blog/2024/04/03/advancing-science-microsoft-and-quantinuum-demonstrate-the-most-reliable-logical-qubits-on-record-with-an-error-rate-800x-better-than-physical-qubits/) that begin to happen more quickly. (Another example is like advances in medical scanning through the use of ML or bioinformatics with medical breakthroughs).\n\n1940 ........... x ... 2045-2100\n\nThat looks linear, but as we all know [we're not on a simple linear technological timeline](https://en.wikipedia.org/wiki/Accelerating_change). Trend lines are exponential with accelerating advances. So we're on a curve with a continuously increasing rate of change that we're acclimating to.\n\nSeeing where we're at is often much easier if we look at where we're heading. More concretely we're entering the point where we'll begin collecting more data from the real world with the goal of continual learning. A big part of that is the [creation of robots and training outside simulations](https://www.freethink.com/robots-ai/embodied-ai). This process will be gradual from now until 2040 helped along with more computation and better sensors. (Also solid-state batteries in the 2030s). These robots will be begin using larger multi-task learning models with visual and audio systems. (Taking all these smaller specialized models and constructing larger models with emergent abilities). The things they'll be capable of, like identifying every object around them, and manipulating them, and discussing their planning will seem mundane rather quickly. (There are already models that have started doing this, but more computation makes iterating on these models faster and the robots more real-time). During this lead-up to and into 2040 there will also be mainstream mixed-reality devices and a drive for low-powered on-compute device and also edge compute and their various ML models and AI accelerator chips. (This will have a lot of overlap with robotics).\n\nInto the 2040s things are fuzzy. Nanofabrication and extremely complex chip production and foundries exist during this time capable of producing and iterating on ideas faster. Sensor hardware and data collection are quite rapid at this point allowing datasets that dwarf what's available now to be created. This is also a time with a massive demand for energy. Companies like Microsoft, Google, and others are already investing (and sometimes researching) into fusion energy. Future datacenters will make the [2028 investment](https://www.reuters.com/technology/microsoft-openai-planning-100-billion-data-center-project-information-reports-2024-03-29/) look very small. Though predicting when they'll have access to fusion power is difficult.\n\nWould a computer begin to think in the extreme is an open question though. General purpose problem solving would be the goal by researchers as more niche problems are solved. There will be a lot of specialized AIs building computer chips and solving problems in a continuously accelerating process. A lot of these might go over people's heads like solving proofs and material science tasks. Finding novel problems for AIs to tackle and seeing how they approach them in the real world will be a large topic.\n\nIt's become trite to say in futurology discussions, but people will be asking where are we probably into the 2050s. (You can be in a singularity with an AGI and still have the progress be gated by energy or manufacturing capacity). A lot of the medical stuff especially is probably after 2060 which is a huge goalpost for many people. There are research projects in that area that'll take decades to figure out.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1712295807,
    "created_utc": 1712295807,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "ky4r49k",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1bw5djw",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_ky4r49k",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t1_ky4327t",
    "permalink": "/r/ChatGPT/comments/1bw5djw/30_years_ago_it_was_a_scary_thoughtand_here_we_are/ky4r49k/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1712295825,
    "saved": false,
    "score": 6,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 6,
    "user_reports": []
}