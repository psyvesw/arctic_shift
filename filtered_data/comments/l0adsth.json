{
    "_meta": {
        "retrieved_2nd_on": 1713658928
    },
    "all_awardings": [],
    "approved_at_utc": null,
    "approved_by": null,
    "archived": false,
    "associated_award": null,
    "author": "MinutePrint7042",
    "author_flair_background_color": null,
    "author_flair_css_class": null,
    "author_flair_richtext": [],
    "author_flair_template_id": null,
    "author_flair_text": null,
    "author_flair_text_color": null,
    "author_flair_type": "text",
    "author_fullname": "t2_admkpq02",
    "author_is_blocked": false,
    "author_patreon_flair": false,
    "author_premium": false,
    "awarders": [],
    "banned_at_utc": null,
    "banned_by": null,
    "body": "There are topics on GPT4 becoming worse already, but the massive decrease in reply quality over the last year has led me to think that there might be more to it than some \u201clazyness\u201d. By now I get the impression that GPT4 is actively becoming lobotomized by more and more restricitions and caps which OpenAI seems to want to hide under the guise of \u201clazyness\u201d. And there are good reasons for that: Server load AND mybe GPT4 was just TOO good at release for proper monetization. My guess is we will see a GPT5 or GPT 4.5 announcement soon, that will involve higher prices and this version will magically gain back all the stuff GPT4 could do perfectly fine last year, but can\u2019t do now. Don\u2019t get me wrong, I don\u2019t want to spread conspiracies here. I am just absolutely confused by the massive decrease in GPT4\u2019s quality since last autumn and OpenAI has not yet answered what is happening there, except their comment on \u201clazyness\u201d. I am or was an OpenAI evangelist, always telling everyone how awesome GPT is and how to use it. But by now I don\u2019t recommed it anymore because it has become really hard to use efficiently. What is happening there, any why?\n\nI want to emphasize that I am giving GPT4 almost exactly the same tasks as a year ago. I would even argue that the tasks I gave it this year are easier to solve since I was working on a complex project last year. Meaning neither my input nor the tasks / code itself has in any way changed, but the results have. A lot. And I\u2019d go as far as saying that it is no sursprise you get the same \u2018since recently I experience a drop in output quality\u2019 since last summer, because the quality of GPT 4 has indeed become worse and worse with each consecutive month passing. The comments by the users were true last summer, and they are true today. Worse answers to the same questions asked before. Which is why I get the feeling this is something done on purpose by now.\n\nWhen I was trying out 4-turbo in the API half of my prompts completely stopped working and I get \u201cI\u2019m unable to fulfill this request.\u201d as the only answer. Asking why leads to the same answer. It seems like some prompts include stuff that gets interpreted as offensive or something - and my prompts are only for work and only for frontend development. So the restrictions seem to be so harsh even the slightest hint of anything that possibly could be offensive got hard-blocked. Which would be fine if it wasn\u2019t triggered by stuff so miniscule it\u2019s almost impossible to find out what was \u201cwrong\u201d in a long prompt.\n\nOh, and it gets worse: All 4 models, no matter which, still massively suffer from a) the lazyness problem introduced last autumn but also b) the apparently \u201cnew\u201d approach by OpenAI to limit server load resulting in placeholders, omits, and straight dementia when after only 2 messages clear and simple orders are forgotten and ignored AND also c) the absolutely contradictory behaviour where 4 goes on explaining every miniscule detail about how it is going to approach the task while not actually DOING the task. Which is then followed by b) if you ask it to do what it just unneccessarily explained to you.\n\nThe absolutely useless wall of text GPT4 now answer to every simple question wasting many many many tokens. GPT4 now spends at least half, sometimes most!, tokens on unneccessarily 1. repeating everything I said again 2. telling me that it is now trying to think about a solution for my problem 3. then telling me how it will approach finding a solution for my problem. And only THEN it MAYBE goes to 4. and starts solving my problem. Most of the time it just stops after 3. having wasted a whole lot of tokens.\n\nOne could even get the impression OpenAI is trying to achieve that people use as much tokens as possible while also reducing the usefullness of the elongated answers so you have to ask over and over again to get your result - using up even more tokens of course. Oh how I wonder what the rea$oning could be behind using such methods \u2026\n\nIn the community forum of OpenAI lots of posts complaining about the quality decrease of GPT are getting censored and deleted by now. If someone does not like what you think about OpenAI / GPT and their products you get silenced.\n\nIn this \u201ccommunity\u201d posts criticizing OpenAI or talking about other models that haven\u2019t become as bad as GPT get censored and deleted. So if you get the impression there is already a lot of posts complaining about the obvious quality drop and moneygrabbing introduced by OpenAI: There was probably even more posts which got deleted because some mod thought they were \u201cdangerous\u201d for OpenAI\u2019s image or something. They even send you a message saying you might edit the post, but the posts will be completely deleted anyways if some mod doesn\u2019t like what you think.\n\nI recommend not getting involved in this sinking ship that just deletes your posts if you post something OpenAI doesn\u2019t like. As if GPT becoming worse and worse wouldn\u2019t be bad enough OpenAI obviously now is also trying to silence people pointing out the obvious. There\u2019s better alternatives out there. Which I can\u2019t mention because the post will be deleted again. Which it will probably anyways.",
    "can_gild": false,
    "can_mod_post": false,
    "collapsed": false,
    "collapsed_because_crowd_control": null,
    "collapsed_reason": null,
    "collapsed_reason_code": null,
    "comment_type": null,
    "controversiality": 0,
    "created": 1713529320,
    "created_utc": 1713529320,
    "distinguished": null,
    "downs": 0,
    "edited": false,
    "gilded": 0,
    "gildings": {},
    "id": "l0adsth",
    "is_submitter": false,
    "likes": null,
    "link_id": "t3_1by23zu",
    "locked": false,
    "mod_note": null,
    "mod_reason_by": null,
    "mod_reason_title": null,
    "mod_reports": [],
    "name": "t1_l0adsth",
    "no_follow": true,
    "num_reports": null,
    "parent_id": "t3_1by23zu",
    "permalink": "/r/ChatGPT/comments/1by23zu/every_thread_about_how_dumblazyuseless_chatgpt_is/l0adsth/",
    "removal_reason": null,
    "replies": "",
    "report_reasons": null,
    "retrieved_on": 1713529336,
    "saved": false,
    "score": 1,
    "score_hidden": false,
    "send_replies": true,
    "stickied": false,
    "subreddit": "ChatGPT",
    "subreddit_id": "t5_7hqomg",
    "subreddit_name_prefixed": "r/ChatGPT",
    "subreddit_type": "public",
    "top_awarded_type": null,
    "total_awards_received": 0,
    "treatment_tags": [],
    "unrepliable_reason": null,
    "ups": 1,
    "user_reports": []
}